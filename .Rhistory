select_if(is.numeric) %>%
map_df(shapiro.test)
shapiro.test(iris$Sepal.Length)
iris %>%
select_if(is.numeric) %>%
map(shapiro.test)
shapiro.test(iris$Sepal.Length)
str(shapiro.test(iris$Sepal.Length))
iris %>%
select_if(is.numeric) %>%
map(shapiro.test) %>%
map_dbl("p.value")
iris %>%
select_if(is.numeric) %>%
map_dbl(~tibble(
mean = mean(.),
q1 = quantile(., probs = .25),
q3 = quantile(., probs = .25))
))
iris %>%
select_if(is.numeric) %>%
map_dbl(~tibble(
mean = mean(.),
q1 = quantile(., probs = .25),
q3 = quantile(., probs = .25))
)
iris %>%
select_if(is.numeric) %>%
map_df(~tibble(
mean = mean(.),
q1 = quantile(., probs = .25),
q3 = quantile(., probs = .75))
)
iris %>%
select_if(is.numeric) %>%
map_df(~tibble(
variable = name(.),
mean = mean(.),
q1 = quantile(., probs = .25),
q3 = quantile(., probs = .75))
)
iris %>%
select_if(is.numeric) %>%
map_df(~tibble(
variable = names(.),
mean = mean(.),
q1 = quantile(., probs = .25),
q3 = quantile(., probs = .75))
)
iris %>%
select_if(is.numeric) %>%
map_df(~tibble(
mean = mean(.),
q1 = quantile(., probs = .25),
q3 = quantile(., probs = .75))
)
iris %>% map_chr(class)
iris %>%
select_if(is.numeric) %>%
map_df(~tibble(
n_dist = n_distinct(.)
)
)
iris %>%
select_if(is.factor) %>%
map_df(~tibble(
n_dist = n_distinct(.)
)
)
iris %>%
select_if(is.factor) %>%
map_df(~tibble(
n_dist = n_distinct(.),
.id = "variable"
)
)
iris %>%
select_if(is.numeric) %>%
map_df(~tibble(
mean = mean(.),
q1 = quantile(., probs = .25),
q3 = quantile(., probs = .75)
),
.id = "variable"
)
iris %>%
select_if(is.factor) %>%
map_df(~tibble(
n_dist = n_distinct(.)
),
.id = "variable"
)
iris %>%
select_if(is.factor) %>%
map_df(~tibble(
n_dist = n_distinct(.),
class = class(.x)
),
.id = "variable"
)
?map2
iris %>%
group_by(species) %>%
map(~tibble(
mean = mean(.)
))
iris %>%
group_by(Species) %>%
map(~tibble(
mean = mean(.)
))
iris %>%
group_by(Species) %>%
select_if(is.numeric) %>%
map(~tibble(
mean = mean(.)
))
iris %>%
group_by(Species) %>%
select_if(is.numeric)
install.packages(c("rgdal", "rworldmap"))
LakeHuron
precip
AirPassengers
as.vector(AirPassengers)
time(AirPassengers)
av.vector(time(AirPassengers))
as.vector(time(AirPassengers))
df_passengers <-
tibble(
time = as.vector(time(AirPassengers)),
passenger = as.vector(AirPassengers)) %>%
mutate(
passenger_low = passenger-10,
passenger_high = passenger+10
)
df_passengers
ggplot(data = df_passengers,
aes(x = time, y = passenger)) +
geom_ribbon(aes(ymin = passenger_low, ymax = passenger_high)) +
geom_line()
ggplot(data = df_passengers,
aes(x = time, y = passenger)) +
geom_ribbon(aes(ymin = passenger_low, ymax = passenger_high),
colour = "grey") +
geom_line()
df_passengers <-
tibble(
time = as.vector(time(AirPassengers)),
passenger = as.vector(AirPassengers)) %>%
mutate(
passenger_low = passenger-20,
passenger_high = passenger+20
)
ggplot(data = df_passengers,
aes(x = time, y = passenger)) +
geom_ribbon(aes(ymin = passenger_low, ymax = passenger_high),
colour = "gray") +
geom_line()
ggplot(data = df_passengers,
aes(x = time, y = passenger)) +
geom_ribbon(aes(ymin = passenger_low, ymax = passenger_high),
fill = "gray") +
geom_line()
p
p <- ggplot(data = films_reduit,
aes(x = estimated_budget, y = gross_revenue)) +
geom_point()
load(url("http://egallic.fr/R/films.rda"))
head(films)
load("donnees/graphiques/films.rda")
head(films)
library(dplyr)
pays_liste <-
c("United States of America", "New Zealand",
"United Kingdom", "Spain")
films_reduit <-
films %>%
filter(country %in% pays_liste)
p <- ggplot(data = films_reduit,
aes(x = estimated_budget, y = gross_revenue)) +
geom_point()
p + annotate("text", x = 1e8, y = 2e9,
label = "sqrt(1-alpha) + beta[i+1]^n", parse = TRUE)
library(latex2exp)
p + annotate("text", x = 1e8, y = 2e9,
label = TeX("$\\sqrt{1-\\alpha} + \\beta^{n}_{i+1}$",
output = "character"),
parse = TRUE)
p <- ggplot(data = films_reduit,
aes(x = estimated_budget,
y = gross_revenue,
colour = country,
size = runtime)) +
geom_point()
p + theme(plot.title.position = "plot")
tx_chomage_2014_T1 <-
tibble(
region = c("Cotes-Darmor","Finistere",
"Ille-et-Vilaine", "Morbihan"),
tx_chomage_2014_T1 = c(8.8, 8.8,7.9, 9.1))
load("donnees/graphiques/rennes_df.rda")
map_fr <- map_data("france")
# Le nom des régions
head(unique(map_fr$region))
# Carte de la France
p_map_fr <-
ggplot(data = map_fr,
aes(x = long, y = lat, group = group, fill = region)) +
geom_polygon() + coord_equal() + scale_fill_discrete(guide = "none")
p_map_fr
# Extrayons les données uniquement pour la Bretagne
ind_bzh <-
grep("armor|finis|vilaine|morb",
unique(map_fr$region), ignore.case = TRUE)
# Voici les noms des départements de la Bretagne, tels qu'ils sont
# stockés dans le package maps
(dep_bzh <- unique(map_fr$region)[ind_bzh])
map_fr_bzh <- map_data("france", region = dep_bzh)
# Carte de la Bretagne
p_map_fr_bzh <-
ggplot(data = map_fr_bzh,
aes(x = long, y = lat, group = group, fill = region)) +
geom_polygon() + coord_equal() + scale_fill_discrete(name = "Département")
p_map_fr_bzh
map_fr_bzh
map_fr_bzh <-
map_data("france", region = dep_bzh) %>%
as_tibble()
map_fr_bzh
map_fr_bzh %>%
left_join(
tx_chomage_2014_T1
)
ggplot(data = map_fr_bzh,
aes(x = long, y = lat, group = group,
fill = tx_chomage_2014_T1)) +
geom_polygon() + coord_equal() +
scale_fill_gradient(name = "Département", low ="#FFFF00", high = "#FF0000")
map_fr_bzh <-
map_fr_bzh %>%
left_join(
tx_chomage_2014_T1
)
p_map_fr_bzh <-
ggplot(data = map_fr_bzh,
aes(x = long, y = lat, group = group,
fill = tx_chomage_2014_T1)) +
geom_polygon() + coord_equal() +
scale_fill_gradient(name = "Département", low ="#FFFF00", high = "#FF0000")
p_map_fr_bzh
mid_range <- function(x) mean(range(x, na.rm = TRUE))
map_fr_bzh %>%
group_by(region)
ddply(map_fr_bzh, .(region), colwise(mid_range, .(lat, long)))
plyr::ddply(map_fr_bzh, .(region), colwise(mid_range, .(lat, long)))
plyr::ddply(map_fr_bzh, plyr::.(region), colwise(mid_range, .(lat, long)))
plyr::ddply(map_fr_bzh, plyr::.(region), plyr::colwise(mid_range, .(lat, long)))
plyr::ddply(map_fr_bzh, plyr::.(region), plyr::colwise(mid_range, plyr::.(lat, long)))
map_fr_bzh %>%
group_by(region) %>%
summarise(lat = mid_range(lat),
long = mid_range(long))
centres <-
map_fr_bzh %>%
group_by(region) %>%
summarise(lat = mid_range(lat),
long = mid_range(long))
centres %>%
left_join(tx_chomage_2014_T1)
centres <-
map_fr_bzh %>%
group_by(region) %>%
summarise(lat = mid_range(lat),
long = mid_range(long))
# Rajout des taux de chômage
centres <-
centres %>%
left_join(tx_chomage_2014_T1) %>%
mutate(label_chomage = str_c(tx_chomage_2014_T1, "%"))
p_map_fr_bzh + geom_label(aes(x = long, y = lat, label = label_chomage), data = centres)
p_map_fr_bzh <-
ggplot(data = map_fr_bzh) +
geom_polygon(aes(x = long, y = lat, group = group,
fill = tx_chomage_2014_T1)) +
coord_equal() +
scale_fill_gradient(name = "Département", low ="#FFFF00", high = "#FF0000")
p_map_fr_bzh
mid_range <- function(x) mean(range(x, na.rm = TRUE))
centres <-
map_fr_bzh %>%
group_by(region) %>%
summarise(lat = mid_range(lat),
long = mid_range(long))
# Rajout des taux de chômage
centres <-
centres %>%
left_join(tx_chomage_2014_T1) %>%
mutate(label_chomage = str_c(tx_chomage_2014_T1, "%"))
p_map_fr_bzh + geom_label(aes(x = long, y = lat, label = label_chomage), data = centres)
install.packages("mapproj")
map_fr <- map_data("france")
# Le nom des régions
head(unique(map_fr$region))
# Carte de la France
p_map_fr <-
ggplot(data = map_fr,
aes(x = long, y = lat, group = group, fill = region)) +
geom_polygon() + coord_equal() + scale_fill_discrete(guide = "none")
p_map_fr
# Extrayons les données uniquement pour la Bretagne
ind_bzh <-
grep("armor|finis|vilaine|morb",
unique(map_fr$region), ignore.case = TRUE)
# Voici les noms des départements de la Bretagne, tels qu'ils sont
# stockés dans le package maps
(dep_bzh <- unique(map_fr$region)[ind_bzh])
map_fr_bzh <-
map_data("france", region = dep_bzh) %>%
as_tibble()
# Carte de la Bretagne
p_map_fr_bzh <-
ggplot(data = map_fr_bzh,
aes(x = long, y = lat, group = group, fill = region)) +
geom_polygon() + coord_equal() + scale_fill_discrete(name = "Département")
p_map_fr_bzh
library("rgdal")
library("maptools")
library("ggplot2")
library("plyr")
load("donnees/graphiques/rennes_df.rda")
p_map_rennes <-
ggplot(data = rennes_df,
aes(x = long, y = lat, group = group)) +
geom_polygon() +
coord_equal()
p_map_rennes
tx_chomage_2014_T1 <-
tibble(
region = c("Cotes-Darmor","Finistere",
"Ille-et-Vilaine", "Morbihan"),
tx_chomage_2014_T1 = c(8.8, 8.8,7.9, 9.1))
# Ajout des valeurs pour chaque région
map_fr_bzh <-
map_fr_bzh %>%
left_join(
tx_chomage_2014_T1
)
# Il suffit de faire dépendre le remplissage de tx_chomage_2014_T1
p_map_fr_bzh <-
ggplot(data = map_fr_bzh) +
geom_polygon(aes(x = long, y = lat, group = group,
fill = tx_chomage_2014_T1)) +
coord_equal() +
scale_fill_gradient(name = "Département", low ="#FFFF00", high = "#FF0000")
p_map_fr_bzh
# Fonction pour trouver le point central du polygone
mid_range <- function(x) mean(range(x, na.rm = TRUE))
centres <-
map_fr_bzh %>%
group_by(region) %>%
summarise(lat = mid_range(lat),
long = mid_range(long))
# Rajout des taux de chômage
centres <-
centres %>%
left_join(tx_chomage_2014_T1) %>%
mutate(label_chomage = str_c(tx_chomage_2014_T1, "%"))
centres
map_fr_bzh
map_fr_bzh %>%
group_by(region) %>%
summarise(lat = mid_range(lat),
long = mid_range(long))
map_fr_bzh
map_fr_bzh$region
map_fr_bzh$region %>% unique()
map_fr_bzh %>%
group_by(region) %>%
summarise(lat = mid_range(lat),
long = mid_range(long))
map_fr_bzh
map_fr_bzh %>%
group_by(region) %>%
summarise(lat = mid_range(lat),
long = mid_range(long))
mid_range <- function(x) mean(range(x, na.rm = TRUE))
map_fr_bzh %>%
group_by(region) %>%
summarise(lat = mid_range(lat),
long = mid_range(long))
map_fr_bzh %>%
group_by(region)
map_fr_bzh %>%
group_by(region) %>%
summarise(lat = mid_range(lat),
long = mid_range(long))
map_fr_bzh %>%
group_by(region) %>%
summarise(lat = min(lat))
map_fr_bzh
detach("package:plyr", unload = TRUE)
library(dplyr)
centres <-
map_fr_bzh %>%
group_by(region) %>%
summarise(lat = mid_range(lat),
long = mid_range(long))
centres
15-6
library(tidyverse)
births$smoke <- factor(births$smoke)
url <- "http://data.princeton.edu/wws509/datasets/phbirths.dat"births <-read.table(url, header = TRUE)head(births)
url <- "http://data.princeton.edu/wws509/datasets/phbirths.dat"
births <-read.table(url, header = TRUE)
births$smoke <-factor(births$smoke)
births$smoke
?fct_relevel
births %>% mutate(smoke = fct_relevel(smoke, TRUE))
births %>% mutate(smoke = fct_relevel(smoke, "TRUE"))
toto <- births %>% mutate(smoke = fct_relevel(smoke, "TRUE"))
toto$smoke
?fct_relevel
mtcars
y <- c(21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8, 16.4, 17.3, 15.2, 10.4, 10.4, 14.7, 32.4, 30.4, 33.9, 21.5, 15.5, 15.2, 13.3, 19.2, 27.3, 26.0, 30.4, 15.8, 19.7, 15.0, 21.4)
hp <-c(110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180, 205, 215, 230, 66, 52, 65, 97, 150, 150, 245, 175, 66, 91, 113, 264, 175, 335, 109)
wt <- c(2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.440, 3.440, 4.070, 3.730, 3.780, 5.250, 5.424, 5.345, 2.200, 1.615, 1.835, 2.465, 3.520, 3.435, 3.840, 3.845, 1.935, 2.140, 1.513, 3.170, 2.770, 3.570, 2.780)
c <- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)
(X <- matrix(c(c, hp, wt), ncol = 3))
t(X)
crossprod(X, X)
t(X) %*% X
a <- crossprod(X, X)
solve(a)
t(X) %*% y
b <- solve(a)
d <- t(X) %*% y
b %*% d
X
summary(lm(mpg ~ hp + wt, data = mtcars))
b %*% d
textes <- c("Je m’évanouis avant d’avoir pu vous révéler",
"le nom du kidnappeur", "et/ou de la kidnappeuse",
"du petit Doug Doug !")
pattern <- "ou"
str_detect(string = textes, pattern = pattern)
str_locate(textes, pattern)
str_which(string = textes, pattern = motif)
textes <- c("Je m’évanouis avant d’avoir pu vous révéler",
"le nom du kidnappeur", "et/ou de la kidnappeuse",
"du petit Doug Doug !")
motif <- "ou"
str_which(string = textes, pattern = motif)
str_which(string = textes, pattern = motif)
grepl(pattern, texte)
grepl(motif, textes)
str_detect(string = textes, pattern = motif)
regexpr(motif, textes)
str_locate(string = textes, pattern = motif)
gregexpr(motif, textes)
gregexpr
gregexpr(pattern = motif, text = textes)
str_locate_all(string = textes, pattern = motif)
regexec(pattern = motif, text = textes)
texte  <- c("J’accepte votre bonjour, Ashley.",
"Et je vous l’échange contre un coucou.",
"Coucou !")
pattern <- "coucou|Ashley"
grepl(pattern, texte)
textes <- c("Mais je ne mange pas, voyons !",
"Mais je ne mange pas", "voyons ! Mais")
grepl(pattern = "^Mais", textes)
grepl(pattern = "je ne mange pas$", textes)
X
solve(X)
sample(1:3, size = 1)
textes <- c("Mais je ne mange pas, voyons !",
"Mais je ne mange pas", "voyons ! Mais")
grepl(pattern = "^Mais", textes)
grepl(pattern = "je ne mange pas$", textes)
str_detect(string = textes, pattern = "^Mais")
str_detect(string = textes, pattern = "je ne mange pas$")
str_detect(string = c("Criquette", "Craquer", "Croquette"),
pattern = "Cr[oi]q", )
grepl("[aeiou]", c("_!", "ALLO", "Allo 9-1-1", "9-1-1"))
str_detect(c("_!", "ALLO", "Allo 9-1-1", "9-1-1"), "[aeiou]")
# Recherche une voyelle majuscule
str_detect(c("_!", "ALLO", "Allo 9-1-1", "9-1-1"), "[AEIOU]")
# Recherche un cacractère numérique
str_detect(c("_!", "Allo", "Allo 9-1-1", "9-1-1"), "[0-9]")
# Recherche un cacractère alphabétique ASCII majuscule
str_detect(c("_!", "Allo", "allo", "ALLO", "9-1-1"), "[A-Z]")
# Recherche un cacractère alphabétique ASCII minuscule
str_detect(c("_!", "Allo", "allo", "ALLO", "9-1-1"), "[a-z]")
# Recherche un cacractère alphabétique (majuscule ou minuscule)
str_detect(c("_!", "Allo", "allo", "ALLO", "9-1-1"), "[A-Za-z]")
# Recherche un cacractère alphanumérique
str_detect(c("_!", "Allo", "allo", "ALLO", "9-1-1"), "[A-Za-z0-9]")
grep("armor|finis|vilaine|morb",
unique(map_fr$region), ignore.case = TRUE)
grep("toto", pattern="o")
str_detect(c("_!", "Allo", "Allo 9-1-1", "911"), "[^0-9]")
str_detect(c("_!", "Allo", "Allo ^ accent", "Allo 9-1-1", "911"), "[0-9^]")
str_detect(c("_!", "All[o", "All]o ^ accent", "Allo 9-1-1", "911"), "[][]")
grep(c("_!", "All[o", "All]o ^ accent", "Allo 9-1-1", "911"), pattern="[][]")
grep(c("_!", "All[o", "All]o ^ accent", "Allo 9-1-1", "911"), "][")
str_detect(c("_!", "All[o", "All]o ^ accent", "Allo 9-1-1", "911"), "[\\]\\[]")
str_detect(c("_!", "All[o", "All]o ^ accent", "Allo 9-1-1", "911"), "[\\[\\[]]")
str_detect(c("_!", "All[o", "All]o ^ accent", "Allo 9-1-1", "911"), "[\\[\\[]")
str_detect(c("_!", "All[o", "All]o ^ accent", "Allo 9-1-1", "911"), "[\\[\\]]")
texte <- c("Lolo travaille au skateshop", "Lolo au skateshop")
grepl("Lolo (travaille )?au skateshop", texte)
